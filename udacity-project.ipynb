{
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": 

"python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
   

   "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
 

     "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      

"pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "nteract": {
      "version": "nteract-front-

end@1.0.0"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      

"source": "from azureml.core import Workspace, Experiment\n\nws = Workspace.from_config()\nexp = 

Experiment(workspace=ws, name=\"udacity-project\")\n\nprint('Workspace name: ' + ws.name, \n      'Azure 

region: ' + ws.location, \n      'Subscription id: ' + ws.subscription_id, \n      'Resource group: ' + 

ws.resource_group, sep = '\\n')\n\nrun = exp.start_logging()",
      "metadata": {
        "gather": {
       

   "logged": 1598275788035
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
    

  "cell_type": "code",
      "source": "from azureml.core.compute import ComputeTarget, AmlCompute\n

\ncluster_name = \"nba\"\n\ncompute_target = ComputeTarget(workspace=ws, name=cluster_name)\nprint

('Cluster target assigned')\n    \n",
      "metadata": {
        "gather": {
          "logged": 

1598275788675
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": 

false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        

},
        "collapsed": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      

"cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nfrom azureml.train.sklearn 

import SKLearn\nfrom azureml.train.hyperdrive.run import PrimaryMetricGoal\nfrom 

azureml.train.hyperdrive.policy import BanditPolicy\nfrom azureml.train.hyperdrive.sampling import 

RandomParameterSampling\nfrom azureml.train.hyperdrive.runconfig import HyperDriveConfig\nfrom 

azureml.train.hyperdrive.parameter_expressions import choice, uniform\n#from azureml.core import 

Environment, ScriptRunConfig\nfrom azureml.core import Workspace, ScriptRunConfig, Environment\nimport os

\n\nsubscription_id = ws.subscription_id\nresource_group = ws.resource_group\nworkspace = ws.name\n

\n#connect to the workspace\nml_client = MLClient(DefaultAzureCredential(), subscription_id, 

resource_group, workspace)\n\n# Specify parameter sampler\nps =  RandomParameterSampling(\n    {\n        

'--C' : choice(0.001,0.01,0.1,1,10),\n        '--max_iter': choice(100,200,300)\n    }\n)\n\n# Specify a 

Policy\npolicy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n\n\n\nif \"training\" not in 

os.listdir():\n    os.mkdir(\"./training\")\n    \nsklearn_env = Environment.from_conda_specification

(name='sklearn-env', file_path='conda_dependencies.yml')\n\nprint ('env created')\n\nsrc = 

ScriptRunConfig(source_directory='./',\n                            script='train.py',\n                   

         compute_target=compute_target,\n                            environment=sklearn_env)\nprint 

('script run config')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
   

   "cell_type": "code",
      "source": "from azureml.core import Workspace, ScriptRunConfig, Environment

\n\n#sklearn_env = Environment.from_conda_specification(name='sklearn-env', 

file_path='conda_dependencies.yml')\n\nhyperdrive_config =  HyperDriveConfig(hyperparameter_sampling=ps, 

\n                                     primary_metric_name='Accuracy',\n                                   

  primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                                     policy=policy,\n   

                                  run_config=src,\n                                     

max_total_runs=16,\n                                     max_concurrent_runs=4)\nprint ('Hyper drive 

config set')\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      

"cell_type": "code",
      "source": "# Submit your hyperdrive run to the experiment and show run details 

with the widget.\n\nhyperdrive_run = exp.submit(hyperdrive_config)\nhyperdrive_run.wait_for_completion

(show_output=True)\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
  

    "cell_type": "code",
      "source": "assert(hyperdrive_run.get_status() == \"Completed\")",
      

"metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      

"source": "import joblib\n\nprint(hyperdrive_run.get_children_sorted_by_primary_metric(top=0, 

reverse=False, discard_no_metric=False))\n\nbest_run = hyperdrive_run.get_best_run_by_primary_metric()\n

\nprint(\"Best run metrics :\",best_run.get_metrics())\n\nprint(\"Best run details :

\",best_run.get_details())\n\nprint(\"Best run file names :\",best_run.get_file_names())\n\n",
      

"metadata": {
        "gather": {
          "logged": 1598276310862
        },
        "jupyter": {
          

"outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          

"transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      

"execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from 

azureml.data.dataset_factory import TabularDatasetFactory\n\n# Create TabularDataset using 

TabularDatasetFactory\n# Data is available at: \n# 

\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-

data/bankmarketing_train.csv\"\n\ntds = TabularDatasetFactory.from_delimited_files

(['https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-

data/bankmarketing_train.csv'])\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
  

  },
    {
      "cell_type": "code",
      "source": "pip install train",
      "metadata": {},
      

"execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from 

train import clean_data\n\n# Use the clean_data function to clean your data.\nx, y = clean_data(tds)",
     

 "metadata": {
        "gather": {
          "logged": 1598275726969
        },
        "jupyter": {
          

"outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          

"transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      

"execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "pip 

install azure-ai-ml",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
     

 "cell_type": "code",
      "source": "from azureml.train.automl import AutoMLConfig\n\n# Set parameters 

for AutoMLConfig\n# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL 

TIME OUT.\n# If you wish to run the experiment longer, you will need to run this notebook in your own\n# 

Azure tenant, which will incur personal costs.\nautoml_config = AutoMLConfig(\n    task='classification',

\n    iterations=30,\n    label_column_name='y',\n    iteration_timeout_minutes=5,\n    

primary_metric='accuracy',\n    training_data=tds,\n    n_cross_validations=2)\n\n#automl_config = 

AutoMLConfig(task=\"classification\",\n#                            X=your_training_features,\n#           

                 y=your_training_labels,\n#                             iterations=30,\n#                  

           iteration_timeout_minutes=5,\n#                             primary_metric=\"AUC_weighted\",\n# 

                            n_cross_validations=5\n#                            )\n",
      "metadata": {
   

     "gather": {
          "logged": 1598275665403
        },
        "jupyter": {
          "outputs_hidden": 

false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            

"deleting": false
          }
        },
        "collapsed": false
      },
      "execution_count": null,
     

 "outputs": []
    },
    {
      "cell_type": "code",
      "source": "pip install -r 

/anaconda/envs/azureml_py38/lib/python3.8/site-

packages/azureml/automl/core/validated_linux_requirements.txt",
      "metadata": {},
      

"execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from 

azureml.core.experiment import Experiment\n\n\n\nexperiment = Experiment(ws, \"automl_sub_experiment

\")\n#print ('exp created')\nrun = experiment.submit(config=automl_config, 

show_output=True)\nrun.wait_for_completion()",
      "metadata": {
        "jupyter": {
          

"outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          

"transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      

"execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "best_run, 

fitted_model = run.get_output()\nprint(best_run)\nprint(fitted_model)",
      "metadata": {},
      

"execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from 

azure.ai.ml.entities import ComputeInstance, AmlCompute\n\nml_client.compute.begin_delete

(cluster_name).wait()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
